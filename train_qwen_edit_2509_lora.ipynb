{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen-Image-Edit-2509 LoRA Training\n",
        "\n",
        "Notebook để train LoRA cho Qwen-Image-Edit-2509 trên RunPod.\n",
        "\n",
        "## Checklist trước khi chạy:\n",
        "- [ ] Đã upload dataset vào thư mục `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "- [ ] Đã upload models vào thư mục `models/`:\n",
        "  - DiT: `models/qwen-image-edit-2509/split_files/diffusion_models/qwen_image_edit_2509_bf16.safetensors`\n",
        "  - VAE: `models/qwen-image-vae/vae/diffusion_pytorch_model.safetensors`\n",
        "  - Text Encoder: `models/qwen-image-text-encoder/split_files/text_encoders/qwen_2.5_vl_7b.safetensors`\n",
        "- [ ] Đã cài đặt dependencies (chạy cell đầu tiên)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Install Dependencies (Chạy cell này TRƯỚC TIÊN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch và dependencies\n",
        "# QUAN TRỌNG: Chạy cell này TRƯỚC TIÊN trước khi chạy các cell khác\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install PyTorch với CUDA (điều chỉnh cu124 hoặc cu128 tùy CUDA version)\n",
        "# RunPod thường dùng CUDA 12.4, nếu khác thì sửa cu124 thành cu128\n",
        "print(\"Step 1: Installing PyTorch with CUDA...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \n",
        "    \"torch\", \"torchvision\", \n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu124\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"⚠ Warning: PyTorch installation may have failed. Trying cu128...\")\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\", \n",
        "        \"torch\", \"torchvision\", \n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cu128\"\n",
        "    ], check=False)\n",
        "\n",
        "# Install project dependencies\n",
        "print(\"\\nStep 2: Installing project dependencies...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"✓ Dependencies installed successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"❌ Dependencies installation failed!\")\n",
        "    print(\"Please check the error messages above.\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cấu hình Paths và Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIGURATION - Điều chỉnh các paths này\n",
        "# ============================================\n",
        "\n",
        "# Base directory (thư mục gốc của repo)\n",
        "BASE_DIR = \".\"\n",
        "\n",
        "# Model paths\n",
        "DIT_MODEL = \"models/qwen_image_edit_2509_bf16.safetensors\"\n",
        "VAE_MODEL = \"models/diffusion_pytorch_model.safetensors\"\n",
        "TEXT_ENCODER_MODEL = \"models/qwen_2.5_vl_7b.safetensors\"\n",
        "\n",
        "# Dataset config\n",
        "DATASET_CONFIG = \"dataset/gendata/vietnamese_dataset_qwen_edit/dataset_config.toml\"\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"output\"\n",
        "OUTPUT_NAME = \"qwen_edit_2509_lora\"\n",
        "\n",
        "# Training parameters\n",
        "LEARNING_RATE = 5e-5\n",
        "MAX_TRAIN_EPOCHS = 16\n",
        "SAVE_EVERY_N_EPOCHS = 1\n",
        "NETWORK_DIM = 16\n",
        "SEED = 42\n",
        "\n",
        "# Memory optimization (cho RTX 3090 hoặc GPU tương tự)\n",
        "USE_FP8_DIT = True  # --fp8_base --fp8_scaled\n",
        "USE_FP8_VL = True   # --fp8_vl\n",
        "USE_GRADIENT_CHECKPOINTING = True\n",
        "USE_BLOCKS_TO_SWAP = False  # Set True nếu vẫn thiếu VRAM, cần 64GB RAM\n",
        "BLOCKS_TO_SWAP = 16\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"Dataset config: {DATASET_CONFIG}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(f\"Output name: {OUTPUT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Kiểm tra Files và Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Kiểm tra các file cần thiết\n",
        "def check_file(path, name):\n",
        "    full_path = Path(BASE_DIR) / path\n",
        "    if full_path.exists():\n",
        "        print(f\"✓ {name}: {full_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"❌ {name} NOT FOUND: {full_path}\")\n",
        "        return False\n",
        "\n",
        "print(\"Checking required files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "files_ok = True\n",
        "files_ok &= check_file(DIT_MODEL, \"DiT Model\")\n",
        "files_ok &= check_file(VAE_MODEL, \"VAE Model\")\n",
        "files_ok &= check_file(TEXT_ENCODER_MODEL, \"Text Encoder Model\")\n",
        "files_ok &= check_file(DATASET_CONFIG, \"Dataset Config\")\n",
        "\n",
        "# Kiểm tra dataset directories\n",
        "dataset_dir = Path(BASE_DIR) / \"dataset/gendata/vietnamese_dataset_qwen_edit\"\n",
        "if (dataset_dir / \"images\").exists():\n",
        "    image_count = len(list((dataset_dir / \"images\").glob(\"*.png\")))\n",
        "    print(f\"✓ Images directory: {image_count} images found\")\n",
        "else:\n",
        "    print(f\"❌ Images directory NOT FOUND: {dataset_dir / 'images'}\")\n",
        "    files_ok = False\n",
        "\n",
        "if (dataset_dir / \"controls\").exists():\n",
        "    control_count = len(list((dataset_dir / \"controls\").glob(\"*.png\")))\n",
        "    print(f\"✓ Controls directory: {control_count} control images found\")\n",
        "else:\n",
        "    print(f\"❌ Controls directory NOT FOUND: {dataset_dir / 'controls'}\")\n",
        "    files_ok = False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "if files_ok:\n",
        "    print(\"✓ All files found! Ready to proceed.\")\n",
        "else:\n",
        "    print(\"❌ Some files are missing. Please check the paths above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cache Latents (Bước 1/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache latents cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    \"src/musubi_tuner/qwen_image_cache_latents.py\",\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--edit_plus\"  # ← Flag cho Edit-2509\n",
        "]\n",
        "\n",
        "print(\"Starting latent caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✓ Latent caching completed successfully!\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"❌ Latent caching failed!\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cache Text Encoder Outputs (Bước 2/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache text encoder outputs cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    \"src/musubi_tuner/qwen_image_cache_text_encoder_outputs.py\",\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--edit_plus\",  # ← Flag cho Edit-2509\n",
        "    \"--batch_size\", \"1\"\n",
        "]\n",
        "\n",
        "# Thêm --fp8_vl nếu cần tiết kiệm VRAM\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")\n",
        "\n",
        "print(\"Starting text encoder output caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✓ Text encoder output caching completed successfully!\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"❌ Text encoder output caching failed!\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train LoRA (Bước 3/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LoRA cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "\n",
        "import os\n",
        "\n",
        "# Tạo output directory nếu chưa có\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Build command\n",
        "cmd = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"--num_cpu_threads_per_process\", \"1\",\n",
        "    \"--mixed_precision\", \"bf16\",\n",
        "    \"src/musubi_tuner/qwen_image_train_network.py\",\n",
        "    \"--dit\", DIT_MODEL,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--edit_plus\",  # ← Flag cho Edit-2509 (BẮT BUỘC)\n",
        "    \"--sdpa\",\n",
        "    \"--mixed_precision\", \"bf16\",\n",
        "    \"--timestep_sampling\", \"shift\",\n",
        "    \"--weighting_scheme\", \"none\",\n",
        "    \"--discrete_flow_shift\", \"2.2\",\n",
        "    \"--optimizer_type\", \"adamw8bit\",\n",
        "    \"--learning_rate\", str(LEARNING_RATE),\n",
        "    \"--max_data_loader_n_workers\", \"2\",\n",
        "    \"--persistent_data_loader_workers\",\n",
        "    \"--network_module\", \"networks.lora_qwen_image\",\n",
        "    \"--network_dim\", str(NETWORK_DIM),\n",
        "    \"--max_train_epochs\", str(MAX_TRAIN_EPOCHS),\n",
        "    \"--save_every_n_epochs\", str(SAVE_EVERY_N_EPOCHS),\n",
        "    \"--seed\", str(SEED),\n",
        "    \"--output_dir\", OUTPUT_DIR,\n",
        "    \"--output_name\", OUTPUT_NAME\n",
        "]\n",
        "\n",
        "# Memory optimization flags\n",
        "if USE_FP8_DIT:\n",
        "    cmd.extend([\"--fp8_base\", \"--fp8_scaled\"])\n",
        "    print(\"✓ Using FP8 optimization for DiT (--fp8_base --fp8_scaled)\")\n",
        "\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")\n",
        "    print(\"✓ Using FP8 optimization for Text Encoder (--fp8_vl)\")\n",
        "\n",
        "if USE_GRADIENT_CHECKPOINTING:\n",
        "    cmd.append(\"--gradient_checkpointing\")\n",
        "    print(\"✓ Using gradient checkpointing\")\n",
        "\n",
        "if USE_BLOCKS_TO_SWAP:\n",
        "    cmd.extend([\"--blocks_to_swap\", str(BLOCKS_TO_SWAP)])\n",
        "    print(f\"✓ Using block swapping (--blocks_to_swap {BLOCKS_TO_SWAP})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting LoRA training for Edit-2509...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Full command:\")\n",
        "print(\" \".join(cmd))\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Chạy training\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"✓ Training completed successfully!\")\n",
        "    print(f\"✓ LoRA saved to: {OUTPUT_DIR}/{OUTPUT_NAME}.safetensors\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"❌ Training failed!\")\n",
        "    print(\"=\" * 60)\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kiểm tra các file output đã được tạo\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "\n",
        "print(f\"Checking output directory: {output_path}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if output_path.exists():\n",
        "    # Tìm các file LoRA\n",
        "    lora_files = list(output_path.glob(f\"{OUTPUT_NAME}*.safetensors\"))\n",
        "    \n",
        "    if lora_files:\n",
        "        print(f\"✓ Found {len(lora_files)} LoRA file(s):\")\n",
        "        for f in sorted(lora_files):\n",
        "            size_mb = f.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(f\"⚠ No LoRA files found matching '{OUTPUT_NAME}*.safetensors'\")\n",
        "    \n",
        "    # Liệt kê tất cả files\n",
        "    all_files = list(output_path.glob(\"*\"))\n",
        "    if all_files:\n",
        "        print(f\"\\nAll files in output directory ({len(all_files)}):\")\n",
        "        for f in sorted(all_files)[:20]:  # Show first 20\n",
        "            if f.is_file():\n",
        "                size_mb = f.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "            else:\n",
        "                print(f\"  - {f.name}/ (directory)\")\n",
        "        if len(all_files) > 20:\n",
        "            print(f\"  ... and {len(all_files) - 20} more files\")\n",
        "else:\n",
        "    print(f\"❌ Output directory not found: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Nếu thiếu VRAM:\n",
        "1. Đảm bảo `USE_FP8_DIT = True` và `USE_FP8_VL = True`\n",
        "2. Đảm bảo `USE_GRADIENT_CHECKPOINTING = True`\n",
        "3. Nếu vẫn thiếu, set `USE_BLOCKS_TO_SWAP = True` (cần 64GB RAM)\n",
        "4. Giảm resolution trong `dataset_config.toml` xuống `[960, 544]`\n",
        "\n",
        "### Nếu gặp lỗi về paths:\n",
        "- Kiểm tra lại các paths trong cell \"Cấu hình Paths\"\n",
        "- Đảm bảo các file models đã được upload đúng vị trí\n",
        "- Đảm bảo dataset đã được upload vào `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "\n",
        "### Nếu training bị dừng giữa chừng:\n",
        "- Checkpoints sẽ được lưu trong `output/`\n",
        "- Có thể resume training bằng cách thêm `--resume` flag (xem docs)\n",
        "\n",
        "### Lưu ý quan trọng:\n",
        "- **Phải dùng `--edit_plus` flag** (không phải `--edit`)\n",
        "- **Model DiT phải là `qwen_image_edit_2509_bf16.safetensors`** (không phải `qwen_image_edit_bf16.safetensors`)\n",
        "- Output sẽ được lưu trong thư mục `output/`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

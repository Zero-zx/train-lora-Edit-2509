{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen-Image-Edit-2509 LoRA Training\n",
        "\n",
        "Notebook ƒë·ªÉ train LoRA cho Qwen-Image-Edit-2509 tr√™n RunPod.\n",
        "\n",
        "## Checklist tr∆∞·ªõc khi ch·∫°y:\n",
        "- [ ] ƒê√£ upload dataset v√†o th∆∞ m·ª•c `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "- [ ] ƒê√£ t·∫£i models v√†o th∆∞ m·ª•c `models/` (t·∫£i tr·ª±c ti·∫øp, kh√¥ng c·∫ßn gi·ªØ c·∫•u tr√∫c th∆∞ m·ª•c g·ªëc):\n",
        "  - **DiT Edit-2509**: `models/qwen_image_edit_2509_bf16.safetensors`\n",
        "    - T·∫£i t·ª´: https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI\n",
        "    - File g·ªëc: `split_files/diffusion_models/qwen_image_edit_2509_bf16.safetensors`\n",
        "  - **VAE**: `models/diffusion_pytorch_model.safetensors`\n",
        "    - T·∫£i t·ª´: https://huggingface.co/Qwen/Qwen-Image\n",
        "    - File g·ªëc: `vae/diffusion_pytorch_model.safetensors`\n",
        "  - **Text Encoder**: `models/qwen_2.5_vl_7b.safetensors`\n",
        "    - T·∫£i t·ª´: https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI\n",
        "    - File g·ªëc: `split_files/text_encoders/qwen_2.5_vl_7b.safetensors`\n",
        "- [ ] ƒê√£ c√†i ƒë·∫∑t dependencies (ch·∫°y cell ƒë·∫ßu ti√™n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Install Dependencies (Ch·∫°y cell n√†y TR∆Ø·ªöC TI√äN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch v√† dependencies\n",
        "# QUAN TR·ªåNG: Ch·∫°y cell n√†y TR∆Ø·ªöC TI√äN tr∆∞·ªõc khi ch·∫°y c√°c cell kh√°c\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install PyTorch v·ªõi CUDA (ƒëi·ªÅu ch·ªânh cu124 ho·∫∑c cu128 t√πy CUDA version)\n",
        "# RunPod th∆∞·ªùng d√πng CUDA 12.4, n·∫øu kh√°c th√¨ s·ª≠a cu124 th√†nh cu128\n",
        "print(\"Step 1: Installing PyTorch with CUDA...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \n",
        "    \"torch\", \"torchvision\", \n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu124\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"‚ö† Warning: PyTorch installation may have failed. Trying cu128...\")\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\", \n",
        "        \"torch\", \"torchvision\", \n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cu128\"\n",
        "    ], check=False)\n",
        "\n",
        "# Install project dependencies\n",
        "print(\"\\nStep 2: Installing project dependencies...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úì Dependencies installed successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚ùå Dependencies installation failed!\")\n",
        "    print(\"Please check the error messages above.\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. C·∫•u h√¨nh Paths v√† Parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIGURATION - ƒêi·ªÅu ch·ªânh c√°c paths n√†y\n",
        "# ============================================\n",
        "\n",
        "# Base directory (th∆∞ m·ª•c g·ªëc c·ªßa repo)\n",
        "BASE_DIR = \".\"\n",
        "\n",
        "# Model paths\n",
        "DIT_MODEL = \"models/qwen_image_edit_2509_bf16.safetensors\"\n",
        "VAE_MODEL = \"models/diffusion_pytorch_model.safetensors\"\n",
        "TEXT_ENCODER_MODEL = \"models/qwen_2.5_vl_7b.safetensors\"\n",
        "\n",
        "# Dataset config\n",
        "DATASET_CONFIG = \"dataset/gendata/vietnamese_dataset_qwen_edit/dataset_config.toml\"\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"output\"\n",
        "OUTPUT_NAME = \"qwen_edit_2509_lora\"\n",
        "\n",
        "# Training parameters\n",
        "LEARNING_RATE = 5e-5\n",
        "MAX_TRAIN_EPOCHS = 16\n",
        "SAVE_EVERY_N_EPOCHS = 1\n",
        "NETWORK_DIM = 16\n",
        "SEED = 42\n",
        "\n",
        "# Memory optimization (cho RTX 3090 ho·∫∑c GPU t∆∞∆°ng t·ª±)\n",
        "USE_FP8_DIT = True  # --fp8_base --fp8_scaled\n",
        "USE_FP8_VL = True   # --fp8_vl\n",
        "USE_GRADIENT_CHECKPOINTING = True\n",
        "USE_BLOCKS_TO_SWAP = False  # Set True n·∫øu v·∫´n thi·∫øu VRAM, c·∫ßn 64GB RAM\n",
        "BLOCKS_TO_SWAP = 16\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"Dataset config: {DATASET_CONFIG}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(f\"Output name: {OUTPUT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Ki·ªÉm tra Files v√† Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Ki·ªÉm tra c√°c file c·∫ßn thi·∫øt\n",
        "def check_file(path, name):\n",
        "    full_path = Path(BASE_DIR) / path\n",
        "    if full_path.exists():\n",
        "        print(f\"‚úì {name}: {full_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"‚ùå {name} NOT FOUND: {full_path}\")\n",
        "        return False\n",
        "\n",
        "print(\"Checking required files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "files_ok = True\n",
        "files_ok &= check_file(DIT_MODEL, \"DiT Model\")\n",
        "files_ok &= check_file(VAE_MODEL, \"VAE Model\")\n",
        "files_ok &= check_file(TEXT_ENCODER_MODEL, \"Text Encoder Model\")\n",
        "files_ok &= check_file(DATASET_CONFIG, \"Dataset Config\")\n",
        "\n",
        "# Ki·ªÉm tra dataset directories\n",
        "dataset_dir = Path(BASE_DIR) / \"dataset/gendata/vietnamese_dataset_qwen_edit\"\n",
        "if (dataset_dir / \"images\").exists():\n",
        "    image_count = len(list((dataset_dir / \"images\").glob(\"*.png\")))\n",
        "    print(f\"‚úì Images directory: {image_count} images found\")\n",
        "else:\n",
        "    print(f\"‚ùå Images directory NOT FOUND: {dataset_dir / 'images'}\")\n",
        "    files_ok = False\n",
        "\n",
        "if (dataset_dir / \"controls\").exists():\n",
        "    control_count = len(list((dataset_dir / \"controls\").glob(\"*.png\")))\n",
        "    print(f\"‚úì Controls directory: {control_count} control images found\")\n",
        "else:\n",
        "    print(f\"‚ùå Controls directory NOT FOUND: {dataset_dir / 'controls'}\")\n",
        "    files_ok = False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "if files_ok:\n",
        "    print(\"‚úì All files found! Ready to proceed.\")\n",
        "else:\n",
        "    print(\"‚ùå Some files are missing. Please check the paths above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cache Latents (B∆∞·ªõc 1/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache latents cho Edit-2509\n",
        "# QUAN TR·ªåNG: Ph·∫£i d√πng --edit_plus flag\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng directory\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Ki·ªÉm tra VAE model file tr∆∞·ªõc khi ch·∫°y\n",
        "vae_path = Path(BASE_DIR) / VAE_MODEL\n",
        "print(\"Validating VAE model file...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not vae_path.exists():\n",
        "    print(f\"‚ùå ERROR: VAE model file not found: {vae_path}\")\n",
        "    print(f\"   Please check the path: {VAE_MODEL}\")\n",
        "    print(f\"   Expected location: {vae_path.resolve()}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Ki·ªÉm tra file size (VAE model th∆∞·ªùng > 100MB)\n",
        "file_size_mb = vae_path.stat().st_size / (1024 * 1024)\n",
        "print(f\"‚úì VAE file found: {vae_path}\")\n",
        "print(f\"  File size: {file_size_mb:.2f} MB\")\n",
        "\n",
        "if file_size_mb < 10:\n",
        "    print(f\"\\n‚ùå ERROR: VAE file seems too small ({file_size_mb:.2f} MB)\")\n",
        "    print(\"   VAE model should be > 100MB. File may be corrupted or incomplete.\")\n",
        "    print(\"\\nüì• C√ÅCH T·∫¢I L·∫†I VAE MODEL:\")\n",
        "    print(\"   1. X√≥a file hi·ªán t·∫°i: rm models/diffusion_pytorch_model.safetensors\")\n",
        "    print(\"   2. T·∫£i l·∫°i t·ª´ HuggingFace:\")\n",
        "    print(\"      - URL: https://huggingface.co/Qwen/Qwen-Image\")\n",
        "    print(\"      - File: vae/diffusion_pytorch_model.safetensors\")\n",
        "    print(\"      - L∆∞u v√†o: models/diffusion_pytorch_model.safetensors\")\n",
        "    print(\"   3. ƒê·∫£m b·∫£o file size > 100MB sau khi t·∫£i xong\")\n",
        "    sys.exit(1)\n",
        "elif file_size_mb < 100:\n",
        "    print(f\"‚ö† WARNING: VAE file seems small ({file_size_mb:.2f} MB)\")\n",
        "    print(\"   Expected size: > 100MB. File may be corrupted.\")\n",
        "\n",
        "# Ki·ªÉm tra file extension\n",
        "if vae_path.suffix != '.safetensors':\n",
        "    print(f\"‚ö† WARNING: VAE file extension is {vae_path.suffix}, expected .safetensors\")\n",
        "\n",
        "# Th·ª≠ ƒë·ªçc header ƒë·ªÉ ki·ªÉm tra file c√≥ h·ª£p l·ªá kh√¥ng\n",
        "try:\n",
        "    import struct\n",
        "    with open(vae_path, 'rb') as f:\n",
        "        # ƒê·ªçc magic number c·ªßa safetensors (8 bytes)\n",
        "        magic = f.read(8)\n",
        "        if magic != b'__SF__\\x00':\n",
        "            print(\"‚ö† WARNING: File may not be a valid safetensors file (magic number mismatch)\")\n",
        "        else:\n",
        "            print(\"‚úì File format check passed (safetensors magic number OK)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö† WARNING: Could not verify file format: {e}\")\n",
        "\n",
        "# Script path\n",
        "script_path = \"src/musubi_tuner/qwen_image_cache_latents.py\"\n",
        "if not Path(script_path).exists():\n",
        "    script_path = \"qwen_image_cache_latents.py\"\n",
        "    if not Path(script_path).exists():\n",
        "        print(f\"‚ùå ERROR: Script not found\")\n",
        "        sys.exit(1)\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    script_path,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--edit_plus\"  # ‚Üê Flag cho Edit-2509 (theo docs)\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting latent caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úì Latent caching completed successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚ùå Latent caching failed!\")\n",
        "    print(\"\\nüîß TROUBLESHOOTING:\")\n",
        "    print(\"\\n1. VAE model file may be CORRUPTED:\")\n",
        "    print(f\"   - File: {vae_path}\")\n",
        "    print(f\"   - Size: {file_size_mb:.2f} MB (should be > 100MB)\")\n",
        "    print(\"   - Error: 'HeaderTooLarge' or 'Header size exceeds maximum'\")\n",
        "    print(\"\\n   üì• C√ÅCH T·∫¢I L·∫†I:\")\n",
        "    print(\"   a) X√≥a file c≈©:\")\n",
        "    print(f\"      rm {vae_path}\")\n",
        "    print(\"   b) T·∫£i l·∫°i t·ª´ HuggingFace:\")\n",
        "    print(\"      - URL: https://huggingface.co/Qwen/Qwen-Image\")\n",
        "    print(\"      - File: vae/diffusion_pytorch_model.safetensors\")\n",
        "    print(\"      - L∆∞u v√†o: models/diffusion_pytorch_model.safetensors\")\n",
        "    print(\"   c) Ki·ªÉm tra file size ph·∫£i > 100MB\")\n",
        "    print(\"\\n2. Check dataset config paths are correct (relative paths)\")\n",
        "    print(\"\\n3. Check error messages above for more details\")\n",
        "    print(\"=\" * 60)\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cache Text Encoder Outputs (B∆∞·ªõc 2/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache text encoder outputs cho Edit-2509\n",
        "# QUAN TR·ªåNG: Ph·∫£i d√πng --edit_plus flag\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    \"src/musubi_tuner/qwen_image_cache_text_encoder_outputs.py\",\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--edit_plus\",  # ‚Üê Flag cho Edit-2509\n",
        "    \"--batch_size\", \"1\"\n",
        "]\n",
        "\n",
        "# Th√™m --fp8_vl n·∫øu c·∫ßn ti·∫øt ki·ªám VRAM\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")\n",
        "\n",
        "print(\"Starting text encoder output caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úì Text encoder output caching completed successfully!\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚ùå Text encoder output caching failed!\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train LoRA (B∆∞·ªõc 3/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LoRA cho Edit-2509\n",
        "# QUAN TR·ªåNG: Ph·∫£i d√πng --edit_plus flag\n",
        "\n",
        "import os\n",
        "\n",
        "# T·∫°o output directory n·∫øu ch∆∞a c√≥\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Build command\n",
        "cmd = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"--num_cpu_threads_per_process\", \"1\",\n",
        "    \"--mixed_precision\", \"bf16\",\n",
        "    \"src/musubi_tuner/qwen_image_train_network.py\",\n",
        "    \"--dit\", DIT_MODEL,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--edit_plus\",  # ‚Üê Flag cho Edit-2509 (B·∫ÆT BU·ªòC)\n",
        "    \"--sdpa\",\n",
        "    \"--mixed_precision\", \"bf16\",\n",
        "    \"--timestep_sampling\", \"shift\",\n",
        "    \"--weighting_scheme\", \"none\",\n",
        "    \"--discrete_flow_shift\", \"2.2\",\n",
        "    \"--optimizer_type\", \"adamw8bit\",\n",
        "    \"--learning_rate\", str(LEARNING_RATE),\n",
        "    \"--max_data_loader_n_workers\", \"2\",\n",
        "    \"--persistent_data_loader_workers\",\n",
        "    \"--network_module\", \"networks.lora_qwen_image\",\n",
        "    \"--network_dim\", str(NETWORK_DIM),\n",
        "    \"--max_train_epochs\", str(MAX_TRAIN_EPOCHS),\n",
        "    \"--save_every_n_epochs\", str(SAVE_EVERY_N_EPOCHS),\n",
        "    \"--seed\", str(SEED),\n",
        "    \"--output_dir\", OUTPUT_DIR,\n",
        "    \"--output_name\", OUTPUT_NAME\n",
        "]\n",
        "\n",
        "# Memory optimization flags\n",
        "if USE_FP8_DIT:\n",
        "    cmd.extend([\"--fp8_base\", \"--fp8_scaled\"])\n",
        "    print(\"‚úì Using FP8 optimization for DiT (--fp8_base --fp8_scaled)\")\n",
        "\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")\n",
        "    print(\"‚úì Using FP8 optimization for Text Encoder (--fp8_vl)\")\n",
        "\n",
        "if USE_GRADIENT_CHECKPOINTING:\n",
        "    cmd.append(\"--gradient_checkpointing\")\n",
        "    print(\"‚úì Using gradient checkpointing\")\n",
        "\n",
        "if USE_BLOCKS_TO_SWAP:\n",
        "    cmd.extend([\"--blocks_to_swap\", str(BLOCKS_TO_SWAP)])\n",
        "    print(f\"‚úì Using block swapping (--blocks_to_swap {BLOCKS_TO_SWAP})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting LoRA training for Edit-2509...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Full command:\")\n",
        "print(\" \".join(cmd))\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Ch·∫°y training\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úì Training completed successfully!\")\n",
        "    print(f\"‚úì LoRA saved to: {OUTPUT_DIR}/{OUTPUT_NAME}.safetensors\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚ùå Training failed!\")\n",
        "    print(\"=\" * 60)\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra c√°c file output ƒë√£ ƒë∆∞·ª£c t·∫°o\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "\n",
        "print(f\"Checking output directory: {output_path}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if output_path.exists():\n",
        "    # T√¨m c√°c file LoRA\n",
        "    lora_files = list(output_path.glob(f\"{OUTPUT_NAME}*.safetensors\"))\n",
        "    \n",
        "    if lora_files:\n",
        "        print(f\"‚úì Found {len(lora_files)} LoRA file(s):\")\n",
        "        for f in sorted(lora_files):\n",
        "            size_mb = f.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(f\"‚ö† No LoRA files found matching '{OUTPUT_NAME}*.safetensors'\")\n",
        "    \n",
        "    # Li·ªát k√™ t·∫•t c·∫£ files\n",
        "    all_files = list(output_path.glob(\"*\"))\n",
        "    if all_files:\n",
        "        print(f\"\\nAll files in output directory ({len(all_files)}):\")\n",
        "        for f in sorted(all_files)[:20]:  # Show first 20\n",
        "            if f.is_file():\n",
        "                size_mb = f.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "            else:\n",
        "                print(f\"  - {f.name}/ (directory)\")\n",
        "        if len(all_files) > 20:\n",
        "            print(f\"  ... and {len(all_files) - 20} more files\")\n",
        "else:\n",
        "    print(f\"‚ùå Output directory not found: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### N·∫øu thi·∫øu VRAM:\n",
        "1. ƒê·∫£m b·∫£o `USE_FP8_DIT = True` v√† `USE_FP8_VL = True`\n",
        "2. ƒê·∫£m b·∫£o `USE_GRADIENT_CHECKPOINTING = True`\n",
        "3. N·∫øu v·∫´n thi·∫øu, set `USE_BLOCKS_TO_SWAP = True` (c·∫ßn 64GB RAM)\n",
        "4. Gi·∫£m resolution trong `dataset_config.toml` xu·ªëng `[960, 544]`\n",
        "\n",
        "### N·∫øu g·∫∑p l·ªói v·ªÅ paths:\n",
        "- Ki·ªÉm tra l·∫°i c√°c paths trong cell \"C·∫•u h√¨nh Paths\"\n",
        "- ƒê·∫£m b·∫£o c√°c file models ƒë√£ ƒë∆∞·ª£c upload ƒë√∫ng v·ªã tr√≠\n",
        "- ƒê·∫£m b·∫£o dataset ƒë√£ ƒë∆∞·ª£c upload v√†o `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "\n",
        "### N·∫øu training b·ªã d·ª´ng gi·ªØa ch·ª´ng:\n",
        "- Checkpoints s·∫Ω ƒë∆∞·ª£c l∆∞u trong `output/`\n",
        "- C√≥ th·ªÉ resume training b·∫±ng c√°ch th√™m `--resume` flag (xem docs)\n",
        "\n",
        "### L∆∞u √Ω quan tr·ªçng:\n",
        "- **Ph·∫£i d√πng `--edit_plus` flag** (kh√¥ng ph·∫£i `--edit`)\n",
        "- **Model DiT ph·∫£i l√† `qwen_image_edit_2509_bf16.safetensors`** (kh√¥ng ph·∫£i `qwen_image_edit_bf16.safetensors`)\n",
        "- Output s·∫Ω ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c `output/`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

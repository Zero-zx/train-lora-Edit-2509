{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen-Image-Edit-2509 LoRA Training\n",
        "\n",
        "Notebook để train LoRA cho Qwen-Image-Edit-2509 trên RunPod.\n",
        "\n",
        "**Tài liệu tham khảo:** [docs/qwen_image.md](docs/qwen_image.md) và [docs/dataset_config.md](docs/dataset_config.md)\n",
        "\n",
        "## Checklist trước khi chạy:\n",
        "- [ ] Đã upload code repo lên RunPod (giữ nguyên cấu trúc thư mục)\n",
        "- [ ] Đã upload dataset vào thư mục `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "- [ ] Đã upload models vào thư mục `models/`:\n",
        "  - DiT: `models/qwen-image-edit-2509/split_files/diffusion_models/qwen_image_edit_2509_bf16.safetensors`\n",
        "  - VAE: `models/qwen-image-vae/vae/diffusion_pytorch_model.safetensors`\n",
        "  - Text Encoder: `models/qwen-image-text-encoder/split_files/text_encoders/qwen_2.5_vl_7b.safetensors`\n",
        "- [ ] Đã chạy cell \"Install Dependencies\" và **RESTART KERNEL** sau khi cài đặt xong\n",
        "- [ ] Đã kiểm tra `dataset_config.toml` có paths đúng (relative paths hoặc Linux paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Install Dependencies (Chạy cell này TRƯỚC TIÊN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch và dependencies\n",
        "# QUAN TRỌNG: Chạy cell này TRƯỚC TIÊN trước khi chạy các cell khác\n",
        "# Sau khi chạy xong, RESTART KERNEL và chạy lại từ cell này\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install PyTorch với CUDA (điều chỉnh cu124 hoặc cu128 tùy CUDA version)\n",
        "# RunPod thường dùng CUDA 12.4, nếu khác thì sửa cu124 thành cu128\n",
        "print(\"Step 1: Installing PyTorch with CUDA...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \n",
        "    \"torch\", \"torchvision\", \n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu124\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"⚠ Warning: PyTorch installation may have failed. Trying cu128...\")\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\", \n",
        "        \"torch\", \"torchvision\", \n",
        "        \"--index-url\", \"https://download.pytorch.org/whl/cu128\"\n",
        "    ], check=False)\n",
        "\n",
        "# Install project dependencies\n",
        "print(\"\\nStep 2: Installing project dependencies...\")\n",
        "result = subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"\n",
        "], check=False)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"✓ Dependencies installed successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\n⚠ QUAN TRỌNG: RESTART KERNEL ngay bây giờ!\")\n",
        "    print(\"   - Jupyter: Kernel -> Restart Kernel\")\n",
        "    print(\"   - Sau đó chạy lại từ cell tiếp theo (cell cấu hình)\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"❌ Dependencies installation failed!\")\n",
        "    print(\"Please check the error messages above.\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cấu hình Paths và Parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIGURATION - Điều chỉnh các paths này\n",
        "# ============================================\n",
        "\n",
        "# Base directory (thư mục gốc của repo)\n",
        "BASE_DIR = \".\"\n",
        "\n",
        "# Model paths\n",
        "DIT_MODEL = \"models/qwen_image_edit_2509_bf16.safetensors\"\n",
        "VAE_MODEL = \"models/diffusion_pytorch_model.safetensors\"\n",
        "TEXT_ENCODER_MODEL = \"models/qwen_2.5_vl_7b.safetensors\"\n",
        "\n",
        "# Dataset config\n",
        "DATASET_CONFIG = \"dataset/gendata/vietnamese_dataset_qwen_edit/dataset_config.toml\"\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"output\"\n",
        "OUTPUT_NAME = \"qwen_edit_2509_lora\"\n",
        "\n",
        "# Training parameters\n",
        "LEARNING_RATE = 5e-5\n",
        "MAX_TRAIN_EPOCHS = 16\n",
        "SAVE_EVERY_N_EPOCHS = 1\n",
        "NETWORK_DIM = 16\n",
        "SEED = 42\n",
        "\n",
        "# Memory optimization (cho RTX 3090 hoặc GPU tương tự)\n",
        "USE_FP8_DIT = True  # --fp8_base --fp8_scaled\n",
        "USE_FP8_VL = True   # --fp8_vl\n",
        "USE_GRADIENT_CHECKPOINTING = True\n",
        "USE_BLOCKS_TO_SWAP = False  # Set True nếu vẫn thiếu VRAM, cần 64GB RAM\n",
        "BLOCKS_TO_SWAP = 16\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"Dataset config: {DATASET_CONFIG}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(f\"Output name: {OUTPUT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Kiểm tra Files và Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "# Thêm src vào Python path để import module (nếu cần)\n",
        "if str(Path(BASE_DIR) / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(Path(BASE_DIR) / \"src\"))\n",
        "\n",
        "# Kiểm tra module có thể import được không\n",
        "try:\n",
        "    import musubi_tuner\n",
        "    print(\"✓ musubi_tuner module imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠ Warning: Cannot import musubi_tuner: {e}\")\n",
        "    print(\"   Make sure you ran 'pip install -e .' and restarted kernel\")\n",
        "\n",
        "# Kiểm tra các file cần thiết\n",
        "def check_file(path, name):\n",
        "    full_path = Path(BASE_DIR) / path\n",
        "    if full_path.exists():\n",
        "        print(f\"✓ {name}: {full_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"❌ {name} NOT FOUND: {full_path}\")\n",
        "        return False\n",
        "\n",
        "print(\"\\nChecking required files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "files_ok = True\n",
        "files_ok &= check_file(DIT_MODEL, \"DiT Model\")\n",
        "files_ok &= check_file(VAE_MODEL, \"VAE Model\")\n",
        "files_ok &= check_file(TEXT_ENCODER_MODEL, \"Text Encoder Model\")\n",
        "files_ok &= check_file(DATASET_CONFIG, \"Dataset Config\")\n",
        "\n",
        "# Kiểm tra dataset directories\n",
        "dataset_dir = Path(BASE_DIR) / \"dataset/gendata/vietnamese_dataset_qwen_edit\"\n",
        "if (dataset_dir / \"images\").exists():\n",
        "    image_count = len(list((dataset_dir / \"images\").glob(\"*.png\")))\n",
        "    print(f\"✓ Images directory: {image_count} images found\")\n",
        "else:\n",
        "    print(f\"❌ Images directory NOT FOUND: {dataset_dir / 'images'}\")\n",
        "    files_ok = False\n",
        "\n",
        "if (dataset_dir / \"controls\").exists():\n",
        "    control_count = len(list((dataset_dir / \"controls\").glob(\"*.png\")))\n",
        "    print(f\"✓ Controls directory: {control_count} control images found\")\n",
        "else:\n",
        "    print(f\"❌ Controls directory NOT FOUND: {dataset_dir / 'controls'}\")\n",
        "    files_ok = False\n",
        "\n",
        "# Kiểm tra và sửa dataset_config.toml nếu có Windows paths\n",
        "config_path = Path(DATASET_CONFIG)\n",
        "if config_path.exists():\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        config_content = f.read()\n",
        "    \n",
        "    # Kiểm tra có Windows paths không\n",
        "    if 'C:/' in config_content or 'C:\\\\' in config_content:\n",
        "        print(\"\\n⚠ WARNING: dataset_config.toml contains Windows paths!\")\n",
        "        print(\"   Auto-fixing to relative paths...\")\n",
        "        \n",
        "        # Tìm và thay thế Windows absolute paths bằng relative paths\n",
        "        # Ví dụ: C:/Work/AI/musubi-tuner/dataset/... -> dataset/...\n",
        "        # Pattern: tìm từ C:/ đến musubi-tuner/ và thay bằng empty\n",
        "        original_content = config_content\n",
        "        \n",
        "        # Thay thế forward slash paths\n",
        "        config_content = re.sub(\n",
        "            r'C:/[^/]+/[^/]+/[^/]+/',\n",
        "            '',\n",
        "            config_content\n",
        "        )\n",
        "        # Thay thế backslash paths\n",
        "        config_content = re.sub(\n",
        "            r'C:\\\\\\\\[^\\\\\\\\]+\\\\\\\\[^\\\\\\\\]+\\\\\\\\[^\\\\\\\\]+\\\\\\\\',\n",
        "            '',\n",
        "            config_content\n",
        "        )\n",
        "        \n",
        "        # Nếu có thay đổi, backup và ghi lại\n",
        "        if config_content != original_content:\n",
        "            # Backup file cũ\n",
        "            backup_path = config_path.with_suffix('.toml.backup')\n",
        "            with open(backup_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(original_content)\n",
        "            \n",
        "            # Ghi file mới\n",
        "            with open(config_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(config_content)\n",
        "            \n",
        "            print(f\"✓ Fixed! Backup saved to: {backup_path}\")\n",
        "            print(\"   Please verify the paths in the config file\")\n",
        "        else:\n",
        "            print(\"   Could not auto-fix. Please manually update paths in dataset_config.toml\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "if files_ok:\n",
        "    print(\"✓ All files found! Ready to proceed.\")\n",
        "else:\n",
        "    print(\"❌ Some files are missing. Please check the paths above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cache Latents (Bước 1/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache latents cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "# Theo docs/qwen_image.md: python src/musubi_tuner/qwen_image_cache_latents.py --dataset_config path/to/toml --vae path/to/vae_model --edit_plus\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Đảm bảo đang ở đúng directory\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Script path - có thể dùng cả root script hoặc src script\n",
        "# Root script: qwen_image_cache_latents.py (import từ src)\n",
        "# Hoặc dùng trực tiếp: src/musubi_tuner/qwen_image_cache_latents.py\n",
        "script_path = \"src/musubi_tuner/qwen_image_cache_latents.py\"\n",
        "if not Path(script_path).exists():\n",
        "    # Thử dùng root script\n",
        "    script_path = \"qwen_image_cache_latents.py\"\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    script_path,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--edit_plus\"  # ← Flag cho Edit-2509 (theo docs)\n",
        "]\n",
        "\n",
        "print(\"Starting latent caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✓ Latent caching completed successfully!\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"❌ Latent caching failed!\")\n",
        "    print(\"Check error messages above for details.\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cache Text Encoder Outputs (Bước 2/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cache text encoder outputs cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "# Theo docs/qwen_image.md: python src/musubi_tuner/qwen_image_cache_text_encoder_outputs.py --dataset_config path/to/toml --text_encoder path/to/text_encoder --edit_plus --batch_size 1\n",
        "\n",
        "import os\n",
        "\n",
        "# Đảm bảo đang ở đúng directory\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Script path\n",
        "script_path = \"src/musubi_tuner/qwen_image_cache_text_encoder_outputs.py\"\n",
        "if not Path(script_path).exists():\n",
        "    script_path = \"qwen_image_cache_text_encoder_outputs.py\"\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    script_path,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--edit_plus\",  # ← Flag cho Edit-2509 (theo docs)\n",
        "    \"--batch_size\", \"1\"\n",
        "]\n",
        "\n",
        "# Thêm --fp8_vl nếu cần tiết kiệm VRAM (theo docs: recommended for <16GB GPUs)\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")\n",
        "\n",
        "print(\"Starting text encoder output caching...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✓ Text encoder output caching completed successfully!\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"❌ Text encoder output caching failed!\")\n",
        "    print(\"Check error messages above for details.\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train LoRA (Bước 3/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LoRA cho Edit-2509\n",
        "# QUAN TRỌNG: Phải dùng --edit_plus flag\n",
        "# Theo docs/qwen_image.md: accelerate launch --num_cpu_threads_per_process 1 --mixed_precision bf16 src/musubi_tuner/qwen_image_train_network.py --dit ... --edit_plus ...\n",
        "\n",
        "import os\n",
        "\n",
        "# Đảm bảo đang ở đúng directory\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Tạo output directory nếu chưa có\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Script path\n",
        "script_path = \"src/musubi_tuner/qwen_image_train_network.py\"\n",
        "if not Path(script_path).exists():\n",
        "    script_path = \"qwen_image_train_network.py\"\n",
        "\n",
        "# Build command theo docs/qwen_image.md\n",
        "cmd = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"--num_cpu_threads_per_process\", \"1\",\n",
        "    \"--mixed_precision\", \"bf16\",\n",
        "    script_path,\n",
        "    \"--dit\", DIT_MODEL,\n",
        "    \"--vae\", VAE_MODEL,\n",
        "    \"--text_encoder\", TEXT_ENCODER_MODEL,\n",
        "    \"--dataset_config\", DATASET_CONFIG,\n",
        "    \"--edit_plus\",  # ← Flag cho Edit-2509 (BẮT BUỘC theo docs)\n",
        "    \"--sdpa\",  # PyTorch scaled dot product attention (theo docs)\n",
        "    \"--mixed_precision\", \"bf16\",  # Recommended for Qwen-Image (theo docs)\n",
        "    \"--timestep_sampling\", \"shift\",  # Default (theo docs)\n",
        "    \"--weighting_scheme\", \"none\",\n",
        "    \"--discrete_flow_shift\", \"2.2\",  # Default (theo docs)\n",
        "    \"--optimizer_type\", \"adamw8bit\",\n",
        "    \"--learning_rate\", str(LEARNING_RATE),\n",
        "    \"--max_data_loader_n_workers\", \"2\",\n",
        "    \"--persistent_data_loader_workers\",\n",
        "    \"--network_module\", \"networks.lora_qwen_image\",  # BẮT BUỘC (theo docs)\n",
        "    \"--network_dim\", str(NETWORK_DIM),\n",
        "    \"--max_train_epochs\", str(MAX_TRAIN_EPOCHS),\n",
        "    \"--save_every_n_epochs\", str(SAVE_EVERY_N_EPOCHS),\n",
        "    \"--seed\", str(SEED),\n",
        "    \"--output_dir\", OUTPUT_DIR,\n",
        "    \"--output_name\", OUTPUT_NAME\n",
        "]\n",
        "\n",
        "# Memory optimization flags (theo docs)\n",
        "if USE_FP8_DIT:\n",
        "    cmd.extend([\"--fp8_base\", \"--fp8_scaled\"])  # For DiT (theo docs)\n",
        "    print(\"✓ Using FP8 optimization for DiT (--fp8_base --fp8_scaled)\")\n",
        "\n",
        "if USE_FP8_VL:\n",
        "    cmd.append(\"--fp8_vl\")  # For Text Encoder, recommended for <16GB GPUs (theo docs)\n",
        "    print(\"✓ Using FP8 optimization for Text Encoder (--fp8_vl)\")\n",
        "\n",
        "if USE_GRADIENT_CHECKPOINTING:\n",
        "    cmd.append(\"--gradient_checkpointing\")  # Available for memory savings (theo docs)\n",
        "    print(\"✓ Using gradient checkpointing\")\n",
        "\n",
        "if USE_BLOCKS_TO_SWAP:\n",
        "    cmd.extend([\"--blocks_to_swap\", str(BLOCKS_TO_SWAP)])\n",
        "    print(f\"✓ Using block swapping (--blocks_to_swap {BLOCKS_TO_SWAP})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting LoRA training for Edit-2509...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Full command:\")\n",
        "print(\" \".join(cmd))\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Chạy training\n",
        "result = subprocess.run(cmd, cwd=BASE_DIR)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"✓ Training completed successfully!\")\n",
        "    print(f\"✓ LoRA saved to: {OUTPUT_DIR}/{OUTPUT_NAME}.safetensors\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"❌ Training failed!\")\n",
        "    print(\"Check error messages above for details.\")\n",
        "    print(\"=\" * 60)\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kiểm tra các file output đã được tạo\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(OUTPUT_DIR)\n",
        "\n",
        "print(f\"Checking output directory: {output_path}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if output_path.exists():\n",
        "    # Tìm các file LoRA\n",
        "    lora_files = list(output_path.glob(f\"{OUTPUT_NAME}*.safetensors\"))\n",
        "    \n",
        "    if lora_files:\n",
        "        print(f\"✓ Found {len(lora_files)} LoRA file(s):\")\n",
        "        for f in sorted(lora_files):\n",
        "            size_mb = f.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(f\"⚠ No LoRA files found matching '{OUTPUT_NAME}*.safetensors'\")\n",
        "    \n",
        "    # Liệt kê tất cả files\n",
        "    all_files = list(output_path.glob(\"*\"))\n",
        "    if all_files:\n",
        "        print(f\"\\nAll files in output directory ({len(all_files)}):\")\n",
        "        for f in sorted(all_files)[:20]:  # Show first 20\n",
        "            if f.is_file():\n",
        "                size_mb = f.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
        "            else:\n",
        "                print(f\"  - {f.name}/ (directory)\")\n",
        "        if len(all_files) > 20:\n",
        "            print(f\"  ... and {len(all_files) - 20} more files\")\n",
        "else:\n",
        "    print(f\"❌ Output directory not found: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Nếu thiếu VRAM:\n",
        "1. Đảm bảo `USE_FP8_DIT = True` và `USE_FP8_VL = True`\n",
        "2. Đảm bảo `USE_GRADIENT_CHECKPOINTING = True`\n",
        "3. Nếu vẫn thiếu, set `USE_BLOCKS_TO_SWAP = True` (cần 64GB RAM)\n",
        "4. Giảm resolution trong `dataset_config.toml` xuống `[960, 544]`\n",
        "\n",
        "### Nếu gặp lỗi về paths:\n",
        "- Kiểm tra lại các paths trong cell \"Cấu hình Paths\"\n",
        "- Đảm bảo các file models đã được upload đúng vị trí\n",
        "- Đảm bảo dataset đã được upload vào `dataset/gendata/vietnamese_dataset_qwen_edit/`\n",
        "\n",
        "### Nếu training bị dừng giữa chừng:\n",
        "- Checkpoints sẽ được lưu trong `output/`\n",
        "- Có thể resume training bằng cách thêm `--resume` flag (xem docs)\n",
        "\n",
        "### Lưu ý quan trọng:\n",
        "- **Phải dùng `--edit_plus` flag** (không phải `--edit`)\n",
        "- **Model DiT phải là `qwen_image_edit_2509_bf16.safetensors`** (không phải `qwen_image_edit_bf16.safetensors`)\n",
        "- Output sẽ được lưu trong thư mục `output/`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

"""
Script Ä‘á»ƒ xem vÃ  kiá»ƒm tra dataset tiáº¿ng Viá»‡t Ä‘Ã£ táº¡o
"""

import json
from pathlib import Path
from PIL import Image
import argparse

def view_dataset(dataset_dir: str, num_samples: int = 10):
    """Xem má»™t sá»‘ máº«u tá»« dataset"""
    dataset_path = Path(dataset_dir)
    metadata_path = dataset_path / "metadata" / "metadata.json"
    images_dir = dataset_path / "images"
    
    if not metadata_path.exists():
        print(f"KhÃ´ng tÃ¬m tháº¥y metadata táº¡i: {metadata_path}")
        return
    
    # Load metadata
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"Tá»•ng sá»‘ áº£nh trong dataset: {len(metadata)}")
    print(f"\nHiá»ƒn thá»‹ {min(num_samples, len(metadata))} máº«u Ä‘áº§u tiÃªn:\n")
    print("=" * 80)
    
    for i, meta in enumerate(metadata[:num_samples]):
        print(f"\náº¢nh #{i+1}:")
        print(f"  ID: {meta['image_id']}")
        print(f"  Text: {meta['text']}")
        print(f"  KÃ­ch thÆ°á»›c: {meta['width']}x{meta['height']}")
        
        # Hiá»ƒn thá»‹ áº£nh náº¿u cÃ³
        img_path = dataset_path / meta['image_path']
        if img_path.exists():
            try:
                img = Image.open(img_path)
                print(f"  ÄÆ°á»ng dáº«n: {img_path}")
                print(f"  Format: {img.format}, Mode: {img.mode}")
            except Exception as e:
                print(f"  Lá»—i khi má»Ÿ áº£nh: {e}")
        else:
            print(f"  âš ï¸ áº¢nh khÃ´ng tá»“n táº¡i: {img_path}")
        
        print("-" * 80)
    
    # Thá»‘ng kÃª
    print(f"\nğŸ“Š Thá»‘ng kÃª:")
    print(f"  - Tá»•ng sá»‘ áº£nh: {len(metadata)}")
    
    # Äáº¿m Ä‘á»™ dÃ i text
    text_lengths = [len(meta['text']) for meta in metadata]
    print(f"  - Äá»™ dÃ i text trung bÃ¬nh: {sum(text_lengths) / len(text_lengths):.1f} kÃ½ tá»±")
    print(f"  - Text ngáº¯n nháº¥t: {min(text_lengths)} kÃ½ tá»±")
    print(f"  - Text dÃ i nháº¥t: {max(text_lengths)} kÃ½ tá»±")
    
    # Äáº¿m sá»‘ tá»« unique
    unique_texts = set(meta['text'] for meta in metadata)
    print(f"  - Sá»‘ text unique: {len(unique_texts)}")
    print(f"  - Tá»· lá»‡ duplicate: {(1 - len(unique_texts) / len(metadata)) * 100:.1f}%")


def main():
    parser = argparse.ArgumentParser(description="Xem dataset áº£nh-vÄƒn báº£n tiáº¿ng Viá»‡t")
    parser.add_argument("--dataset_dir", type=str, default="vietnamese_dataset",
                       help="ThÆ° má»¥c dataset (default: vietnamese_dataset)")
    parser.add_argument("--num_samples", type=int, default=10,
                       help="Sá»‘ máº«u Ä‘á»ƒ hiá»ƒn thá»‹ (default: 10)")
    
    args = parser.parse_args()
    view_dataset(args.dataset_dir, args.num_samples)


if __name__ == "__main__":
    main()

